# Pipeline.py (updated & hardened end-to-end)
# Step 1: Extract text from the Confluence PDF (hard-coded path)
# Step 2: Parse key fields (NO .md DRAFT)
# Step 3: Fetch ALL KB articles via Zoho Desk API and match the title (print decision + all titles checked)
# Step 3b: Pair Confluence & Zoho PDFs by title from folders, build lossless merged manual(s)
# Step 4: Email the NEWLY CREATED merged PDF to manager (attachment if available) and optionally wait for the reply

from pathlib import Path
import re
import json
import sys
import os  # env vars
import itertools
import difflib
from datetime import datetime, timedelta, timezone
from typing import List, Tuple, Dict, Optional

# ----------------------
# .env loader (critical)
# ----------------------
try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

# ======================
# Paths / constants
# ======================
PDF_PATH = Path(r"C:\Users\usman\Downloads\Droom Task\Drooms_AutomationTask\confluence\PROD-Batch Redaction (1.1)_ Final Product Description.pdf")
BASE_OUT = Path(r"C:\Users\usman\Downloads\Droom Task\Drooms_AutomationTask")
OUT_TEXT_DIR = BASE_OUT / "extracted_text"
OUT_TEXT_DIR.mkdir(parents=True, exist_ok=True)
OUT_TXT = OUT_TEXT_DIR / "Batch_Redaction_1_1.txt"

OUTPUT_DIR = Path(os.getenv("OUTPUT_DIR", str(BASE_OUT / "merged_manuals")))
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

PDF_TITLE_OVERRIDE = None
KB_BASE = "https://drooms.zohodesk.eu"

# ======================
# Zoho Desk API
# ======================
ZOHO_API_BASE = os.getenv("ZOHO_API_BASE", "https://desk.zoho.eu/api/v1")
ZOHO_OAUTH_TOKEN = os.getenv("ZOHO_OAUTH_TOKEN", "")
ZOHO_ORG_ID = os.getenv("ZOHO_ORG_ID", "20109871887")

# ======================
# Folder matching config
# ======================
CONFLUENCE_PATH = Path(os.getenv("CONFLUENCE_PATH", str(BASE_OUT / "confluence")))
ZOHO_PATH       = Path(os.getenv("ZOHO_PATH",       str(BASE_OUT / "zoho")))
TITLE_THRESHOLD = float(os.getenv("TITLE_THRESHOLD", "0.50"))  # 0.50 default

# ======================
# PDF creation utilities
# ======================
try:
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.units import mm
    from reportlab.lib.enums import TA_JUSTIFY
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    REPORTLAB_OK = True
except Exception:
    REPORTLAB_OK = False

try:
    from pypdf import PdfWriter
    PYPDF_OK = True
except Exception:
    PYPDF_OK = False

MARGIN = 18 * (mm if REPORTLAB_OK else 1)

# ======================
# Small utility
# ======================
def _is_valid_file(p):
    try:
        return isinstance(p, Path) and p.is_file()
    except Exception:
        return False

# ======================
# PDF text extraction & parsing helpers
# ======================
def extract_text_from_pdf(pdf_path: Path) -> str:
    text = ""
    try:
        import PyPDF2  # pip install PyPDF2
        with open(pdf_path, "rb") as f:
            reader = PyPDF2.PdfReader(f)
            for page in reader.pages:
                text += page.extract_text() or ""
        if text.strip():
            return text
    except Exception as e:
        print("[info] PyPDF2 failed, trying pdfminerâ€¦", e, file=sys.stderr)

    try:
        from pdfminer_high_level import extract_text as pdfminer_extract_text  # pip install pdfminer.six
    except Exception:
        from pdfminer.high_level import extract_text as pdfminer_extract_text

    try:
        return pdfminer_extract_text(str(pdf_path))
    except Exception as e:
        return f"<<Failed to extract PDF text: {e}>>"

def extract_title(text: str, fallback: str = "Untitled Article") -> str:
    for line in text.splitlines():
        s = line.strip()
        if s:
            s = re.sub(r"^[#*\-\d.\s]+", "", s).strip()
            if 5 <= len(s) <= 140:
                return s
    return fallback

def extract_release_version(text: str) -> str:
    m = re.search(r"\b(?:v|version|release)\s*[:\-]?\s*([0-9]+(?:\.[0-9]+){0,3})\b", text, flags=re.I)
    return m.group(1) if m else ""

def extract_release_date(text: str) -> str:
    patterns = [
        r"\b(20\d{2}-\d{2}-\d{2})\b",
        r"\b(\d{1,2}/\d{1,2}/20\d{2})\b",
        r"\b(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec)[a-z]*\s+\d{1,2},\s+20\d{2}\b",
    ]
    for p in patterns:
        m = re.search(p, text, flags=re.I)
        if m:
            return m.group(1)
    return ""

def extract_bullets(text: str):
    bullets = re.findall(r"(?m)^\s*(?:[-*]|[\d]+\.)\s+(.+)$", text)
    return [b.strip() for b in bullets]

def classify_article_type(text: str) -> str:
    t = text.lower()
    if any(k in t for k in ["troubleshoot", "error", "fix failed", "how to resolve", "workaround"]):
        return "troubleshooting"
    if any(k in t for k in ["bug fix", "resolved issue", "hotfix", "patch"]):
        return "bugfix"
    if any(k in t for k in ["new feature", "introduc", "launch", "available now", "added a new"]):
        return "new_feature"
    if any(k in t for k in ["updated", "improved", "enhanced", "changed behavior", "ui update", "1.1"]):
        return "feature_update"
    return "process_update"

def extract_summary(text: str) -> str:
    sentences = re.split(r"(?<=[.!?])\s+", text.strip())
    return " ".join(sentences[:3])[:600]

def guess_product_area(text: str) -> str:
    areas = ["redaction", "virtual data room", "q&a", "permissions", "login", "api", "search", "viewer", "document", "mobile"]
    t = text.lower()
    for a in areas:
        if a in t:
            return a
    return ""

def extract_prereqs(text: str):
    candidates = []
    for line in text.splitlines():
        if any(k in line.lower() for k in ["prereq", "require", "you need", "before you", "permissions required"]):
            s = re.sub(r"^[#*\-\d.\s]+", "", line).strip()
            candidates.append(s)
    return candidates[:6]

def extract_steps(text: str):
    steps = re.findall(r"(?m)^\s*(?:\d+[\).\s])\s*(.+)$", text)
    if steps:
        return [s.strip() for s in steps][:12]
    verbs = ("select", "click", "open", "go to", "choose", "type", "press", "save", "define")
    bullets = extract_bullets(text)
    stepish = [b for b in bullets if any(v in b.lower() for v in verbs)]
    return stepish[:12]

def extract_breaking_changes(text: str):
    candidates = []
    for para in re.split(r"\n\s*\n", text):
        if "breaking" in para.lower() or "deprecat" in para.lower():
            found = extract_bullets(para)
            candidates.extend(found if found else [para.strip()])
    return [c[:220] for c in candidates[:5]]

# ======================
# Zoho Desk listing + fuzzy match
# ======================
def list_all_kb_articles_via_api() -> list:
    try:
        import requests
    except Exception as e:
        print(f"[error] requests not available: {e}")
        return []

    url = f"{ZOHO_API_BASE}/articles"
    headers = {
        "Authorization": f"Zoho-oauthtoken {ZOHO_OAUTH_TOKEN}",
        "orgId": ZOHO_ORG_ID,
        "Accept": "application/json",
        "User-Agent": "KB-Matcher/1.3 (+local-script)",
    }

    try:
        resp = requests.get(url, headers=headers, timeout=30)
        print(f"[ZohoDesk] GET {url} -> {resp.status_code}")
    except Exception as e:
        print(f"[error] Zoho Desk API request failed: {e}")
        return []

    if not resp.ok:
        print("[error] Zoho Desk API returned non-OK status.")
        try:
            print("[error] Body:", resp.text[:1000])
        except Exception:
            pass
        return []

    try:
        data = resp.json()
    except Exception as e:
        print("[error] Failed to parse JSON:", e)
        print("[error] Raw body (first 1k):", (resp.text or "")[:1000])
        return []

    items = None
    if isinstance(data, list):
        items = data
    elif isinstance(data, dict):
        items = data.get("data") or data.get("articles") or data.get("items") or data.get("resources")
        if isinstance(items, dict) and "data" in items:
            items = items.get("data")

    if not isinstance(items, list):
        print("[warn] No articles found in response.")
        return []

    articles = []
    for it in items:
        title = (it.get("title") or it.get("name") or "").strip()
        if not title:
            continue
        url = it.get("webUrl") or it.get("webURL") or it.get("portalUrl") or it.get("url") or ""
        if not url and it.get("id"):
            url = f"{KB_BASE}/portal/en/kb/articles/{it['id']}"
        articles.append({"id": it.get("id"), "title": title, "url": url, "raw": it})

    # Deduplicate by id/title
    seen_ids = set()
    seen_titles = set()
    deduped = []
    for a in articles:
        key = a.get("id") or a.get("title", "").lower()
        if key and key not in seen_ids and a.get("title", "").strip():
            deduped.append(a); seen_ids.add(key); seen_titles.add(a["title"].lower())
        elif a.get("title", "").lower() not in seen_titles and a.get("title", "").strip():
            deduped.append(a); seen_titles.add(a["title"].lower())

    return deduped

def _best_title_match(query_title: str, candidates: list) -> tuple:
    if not candidates:
        return None, -1.0
    from difflib import SequenceMatcher
    def normalize(t):
        t = t.lower()
        t = re.sub(r"\b(version|update|release)\b", "", t)
        t = re.sub(r"\b\d+(\.\d+)*\b", "", t)
        t = re.sub(r"[^a-z0-9]+", " ", t).strip()
        return t
    def sim(a, b):
        return SequenceMatcher(None, normalize(a), normalize(b)).ratio()
    best, best_score = None, -1.0
    for c in candidates:
        title = c.get("title", "")
        if not title:
            continue
        s = sim(query_title, title)
        if s > best_score:
            best_score = s; best = c
    return best, best_score

def find_kb_title_match_via_api(pdf_title: str) -> dict:
    decision = {
        "action": "new",
        "query_title": pdf_title,
        "matched_title": None,
        "matched_url": None,
        "matched_id": None,
        "score": 0.0,
        "candidates": [],
        "api_base": ZOHO_API_BASE,
    }
    articles = list_all_kb_articles_via_api()
    candidates = []
    for a in articles:
        if not a.get("title"):
            continue
        candidates.append({"title": a.get("title", "").strip(), "url": a.get("url") or "", "id": a.get("id")})
    decision["candidates"] = candidates

    best, best_score = _best_title_match(pdf_title, candidates)
    THRESHOLD = 0.85
    if best and best_score >= THRESHOLD:
        decision.update({
            "action": "update",
            "matched_title": best["title"],
            "matched_url": best.get("url"),
            "matched_id": best.get("id"),
            "score": round(float(best_score), 4),
        })
    elif best:
        decision.update({
            "matched_title": best["title"],
            "matched_url": best.get("url"),
            "matched_id": best.get("id"),
            "score": round(float(best_score), 4),
        })
    return decision

# ======================
# Folder title-matching + merging logic
# ======================
def ensure_dir(path: Path):
    if not path or not path.exists() or not path.is_dir():
        raise FileNotFoundError(f"Folder not found: {path}")

def list_pdf_files(folder: Path) -> List[str]:
    return sorted([f.name for f in folder.glob("*.pdf")])

def get_title_from_filename(filename: str) -> str:
    name, _ = os.path.splitext(filename)
    name = name.lower()
    for token in ["prod", "duplicate", "final", "product description", "version",
                  "(", ")", "_", "-", "â€“", "â€”"]:
        name = name.replace(token, " ")
    return " ".join(name.split()).strip()

def best_unique_pairs(conf_files: List[str], zoho_files: List[str], threshold: float) -> List[Tuple[str, str, float]]:
    conf_titles = {c: get_title_from_filename(c) for c in conf_files}
    zoho_titles = {z: get_title_from_filename(z) for z in zoho_files}
    scored: List[Tuple[str, str, float]] = []
    for c, z in itertools.product(conf_files, zoho_files):
        s = difflib.SequenceMatcher(None, conf_titles[c], zoho_titles[z]).ratio()
        if s >= threshold:
            scored.append((c, z, round(s, 2)))
    scored.sort(key=lambda x: x[2], reverse=True)
    used_c, used_z, result = set(), set(), []
    for c, z, s in scored:
        if c in used_c or z in used_z:
            continue
        result.append((c, z, s))
        used_c.add(c); used_z.add(z)
    return result

def render_simple_page_pdf(title: str, subtitle: str, body_lines: list, out_path: Path):
    if not REPORTLAB_OK:
        raise RuntimeError("ReportLab is required to render cover/divider pages. Install reportlab.")
    out_path.parent.mkdir(parents=True, exist_ok=True)
    doc = SimpleDocTemplate(str(out_path), pagesize=A4,
                            leftMargin=MARGIN, rightMargin=MARGIN,
                            topMargin=MARGIN, bottomMargin=MARGIN)
    styles = getSampleStyleSheet()
    h1 = ParagraphStyle('H1', parent=styles['Heading1'], fontName='Helvetica-Bold', fontSize=18, spaceAfter=10)
    h2 = ParagraphStyle('H2', parent=styles['Heading2'], fontName='Helvetica-Bold', fontSize=14, spaceAfter=8)
    base = ParagraphStyle('Base', parent=styles['Normal'], fontName='Helvetica', fontSize=11,
                          leading=16, alignment=TA_JUSTIFY, spaceAfter=6)
    story = []
    if title:   story.append(Paragraph(title, h1))
    if subtitle:
        story.append(Paragraph(subtitle, h2))
        story.append(Spacer(1, 6))
    for ln in body_lines:
        story.append(Paragraph(ln, base))
    doc.build(story)

def merge_pdfs_lossless(zoho_pdf: Path, conf_pdf: Path, cover_pdf: Optional[Path], divider_pdf: Optional[Path], out_pdf: Path):
    if not PYPDF_OK:
        raise RuntimeError("pypdf is required for lossless merge. Install pypdf.")
    writer = PdfWriter()
    if cover_pdf and cover_pdf.exists():
        writer.append(str(cover_pdf))
    writer.append(str(zoho_pdf))
    if divider_pdf and divider_pdf.exists():
        writer.append(str(divider_pdf))
    writer.append(str(conf_pdf))
    out_pdf.parent.mkdir(parents=True, exist_ok=True)
    with open(out_pdf, "wb") as f_out:
        writer.write(f_out)
    writer.close()

def build_lossless_manuals_from_folders(conf_dir: Path, zoho_dir: Path, out_dir: Path, threshold: float) -> Dict[str, Path]:
    ensure_dir(conf_dir)
    ensure_dir(zoho_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    print("ðŸ” Scanning folders...")
    conf_files = list_pdf_files(conf_dir)
    zoho_files = list_pdf_files(zoho_dir)
    print(f"Confluence PDFs ({len(conf_files)}): {conf_files}")
    print(f"Zoho KB PDFs   ({len(zoho_files)}): {zoho_files}")
    print(f"\nðŸ§® Matching (1:1) by title with threshold â‰¥ {threshold} ...")
    pairs = best_unique_pairs(conf_files, zoho_files, threshold)
    if not pairs:
        print("No pairs met the threshold. Skipping merge.")
        return {}
    print("\nðŸ“˜ Matched pairs:")
    for c, z, s in pairs:
        print(f" - {c}  â†”  {z}   (similarity={s})")
    created: Dict[str, Path] = {}
    print("\nðŸ› ï¸ Building lossless manuals...")
    for conf_f, kb_f, score in pairs:
        conf_path = conf_dir / conf_f
        kb_path   = zoho_dir / kb_f
        cover_path = out_dir / "_tmp_cover.pdf"
        render_simple_page_pdf(
            title=os.path.splitext(kb_f)[0],
            subtitle="Updated Manual",
            body_lines=[
                f"Compiled on {datetime.now().strftime('%Y-%m-%d')}",
                "This manual merges the original Knowledge Base article (as-is) with the matching Confluence document."
            ],
            out_path=cover_path
        )
        divider_path = out_dir / "_tmp_divider.pdf"
        render_simple_page_pdf(
            title="Additions from Confluence",
            subtitle=os.path.splitext(conf_f)[0],
            body_lines=["The following pages contain the Confluence document exactly as in the original."],
            out_path=divider_path
        )
        lossless_name = os.path.splitext(kb_f)[0] + " (LOSSLESS UPDATED MANUAL).pdf"
        lossless_path = out_dir / lossless_name
        merge_pdfs_lossless(kb_path, conf_path, cover_path, divider_path, lossless_path)
        print(f"âœ… Lossless: {lossless_path}")
        created[conf_f] = lossless_path
    return created

# ======================
# Email helpers (Gmail SMTP + IMAP) â€” hardened
# ======================
import smtplib, imaplib, time, mimetypes, email
from email.message import EmailMessage
from email.header import decode_header, make_header

def send_email_with_attachment_smtp(
    subject: str,
    body: str,
    to_addrs: list,
    cc_addrs: list,
    attachment_path: Path,
    smtp_user: str,
    smtp_pass: str,
    smtp_host: str = "smtp.gmail.com",
) -> None:
    import ssl, smtplib, mimetypes
    from email.message import EmailMessage

    msg = EmailMessage()
    msg["Subject"] = str(subject)
    msg["From"] = smtp_user
    msg["To"] = ", ".join(to_addrs)
    if cc_addrs:
        msg["Cc"] = ", ".join(cc_addrs)
    msg.set_content(str(body))

    if attachment_path and attachment_path.exists():
        ctype, _ = mimetypes.guess_type(str(attachment_path))
        if not ctype: ctype = "application/octet-stream"
        maintype, subtype = ctype.split("/", 1)
        with open(attachment_path, "rb") as f:
            msg.add_attachment(
                f.read(), maintype=maintype, subtype=subtype, filename=attachment_path.name
            )

    ctx = ssl.create_default_context()
    try:
        with smtplib.SMTP_SSL(smtp_host, 465, context=ctx, timeout=60) as s:
            if os.getenv("SMTP_DEBUG", "0") == "1": s.set_debuglevel(1)
            s.login(smtp_user, smtp_pass)
            s.send_message(msg)
            return
    except smtplib.SMTPServerDisconnected as e:
        print("[warn] SMTP_SSL disconnected early:", e)
    except Exception as e:
        print(f"[warn] SMTP_SSL(465) failed: {e}. Falling back to STARTTLSâ€¦")

    with smtplib.SMTP(smtp_host, 587, timeout=60) as s:
        if os.getenv("SMTP_DEBUG", "0") == "1": s.set_debuglevel(1)
        s.ehlo(); s.starttls(); s.ehlo()
        s.login(smtp_user, smtp_pass)
        s.send_message(msg)

def _get_email_text(payload) -> str:
    if payload.is_multipart():
        for part in payload.walk():
            ctype = part.get_content_type()
            disp = part.get("Content-Disposition", "")
            if ctype == "text/plain" and "attachment" not in (disp or "").lower():
                try:
                    return part.get_content().strip()
                except Exception:
                    try:
                        return part.get_payload(decode=True).decode(part.get_content_charset() or "utf-8", errors="ignore").strip()
                    except Exception:
                        continue
        part = payload.get_payload(0)
        try:
            return part.get_content().strip()
        except Exception:
            return ""
    else:
        try:
            return payload.get_content().strip()
        except Exception:
            return payload.get_payload(decode=True).decode(payload.get_content_charset() or "utf-8", errors="ignore").strip()

def wait_for_reply_imap(
    original_subject: str,
    expect_from: str,
    imap_user: str,
    imap_pass: str,
    imap_host: str = "imap.gmail.com",
    mailbox: str = "INBOX",
    timeout_minutes: int = 15,
    poll_interval_seconds: int = 15,
) -> dict:
    deadline = datetime.now(timezone.utc) + timedelta(minutes=timeout_minutes)
    subject_tokens = [original_subject.lower(), f"re: {original_subject}".lower()]
    while datetime.now(timezone.utc) < deadline:
        try:
            conn = imaplib.IMAP4_SSL(imap_host, 993)
            conn.login(imap_user, imap_pass)
            conn.select(mailbox)
            since = (datetime.utcnow() - timedelta(days=1)).strftime("%d-%b-%Y")
            typ, data = conn.search(None, f'(SINCE {since})')
            if typ != "OK":
                conn.logout(); time.sleep(poll_interval_seconds); continue
            ids = data[0].split()
            for msg_id in reversed(ids):
                typ, msgdata = conn.fetch(msg_id, "(RFC822)")
                if typ != "OK" or not msgdata or not msgdata[0]: continue
                raw = msgdata[0][1]
                payload = email.message_from_bytes(raw)
                from_hdr = str(make_header(decode_header(payload.get("From", ""))))
                subj_hdr = str(make_header(decode_header(payload.get("Subject", ""))))
                date_hdr = payload.get("Date", "")
                subj_l = subj_hdr.lower()
                if expect_from.lower() in from_hdr.lower() and any(tok in subj_l for tok in subject_tokens):
                    body_text = _get_email_text(payload)
                    conn.logout()
                    return {"found": True, "from": from_hdr, "subject": subj_hdr, "date": date_hdr, "body": (body_text or "").strip()[:5000]}
            conn.logout()
        except Exception:
            pass
        time.sleep(poll_interval_seconds)
    return {"found": False}

# ======================
# Main flow
# ======================
def main():
    # Dependencies (non-fatal)
    if not REPORTLAB_OK:
        print("[warn] ReportLab not installed (cover/divider pages). Run: pip install reportlab")
    if not PYPDF_OK:
        print("[warn] pypdf not installed (lossless merging). Run: pip install pypdf")

    if not PDF_PATH.exists():
        print(f"[error] PDF not found:\n{PDF_PATH}")
        sys.exit(1)

    # ---- Step 1: extract
    print(">> Step 1: Extracting text from PDFâ€¦")
    pdf_text = extract_text_from_pdf(PDF_PATH)
    OUT_TXT.write_text(pdf_text, encoding="utf-8", errors="ignore")
    print("\nâœ… Extracted text preview (first 500 chars):\n")
    print((pdf_text[:500] if isinstance(pdf_text, str) else "<<no text>>").replace("\n", " "))
    print("\nFull text saved to:", OUT_TXT)

    # ---- Step 2: parse (no .md draft)
    print("\n>> Step 2: Parsing fields (NO .md draft generated)â€¦")
    extracted_text = pdf_text if isinstance(pdf_text, str) else ""
    derived_title = extract_title(extracted_text, fallback=PDF_PATH.stem)
    meta = {
        "title": derived_title[:140],
        "article_type": classify_article_type(extracted_text),
        "audience": "both",
        "product_area": guess_product_area(extracted_text),
        "tags": ["auto-generated", "kb-draft-removed"],
        "summary": extract_summary(extracted_text),
        "prerequisites": extract_prereqs(extracted_text),
        "steps": extract_steps(extracted_text),
        "release_version": extract_release_version(extracted_text),
        "release_date": extract_release_date(extracted_text),
        "breaking_changes": extract_breaking_changes(extracted_text),
        "sources": [str(PDF_PATH)],
    }
    print("\n==== Parsed Fields (key) ====")
    print("Title:           ", meta["title"])
    print("Article Type:    ", meta["article_type"])
    print("Product Area:    ", meta["product_area"])
    print("Release Version: ", meta["release_version"] or "(not found)")
    print("Release Date:    ", meta["release_date"] or "(not found)")
    print("Steps Detected:  ", len(meta["steps"]))
    print("Prereqs Detected:", len(meta["prerequisites"]))

    # ---- Step 3: Zoho Desk titles
    print("\n>> Step 3: Fetching KB articles via Zoho Desk API and matching titleâ€¦")
    query_title = PDF_TITLE_OVERRIDE if (isinstance(PDF_TITLE_OVERRIDE, str) and PDF_TITLE_OVERRIDE.strip()) else meta["title"]
    decision = find_kb_title_match_via_api(query_title)
    print("\nQuery Title (searched):", decision.get("query_title") or query_title)
    all_titles = [c["title"] for c in decision.get("candidates", [])]
    if all_titles:
        print("\nAll KB Titles Found (checked for match):")
        for idx, t in enumerate(all_titles, 1):
            print(f"  {idx}. {t}")
    else:
        print("\nNo KB articles returned by the API or titles unavailable.")
    matched_title = decision.get("matched_title")
    matched_url = decision.get("matched_url")
    matched_id = decision.get("matched_id")
    score = decision.get("score", 0.0)
    if decision.get("action") == "update":
        print(f"\nDecision: UPDATE existing KB")
        print(f"Matched Title: {matched_title}")
        print(f"Article ID:    {matched_id or '(unknown)'}")
        print(f"URL:           {matched_url or '(none)'}")
        print(f"Score:         {score:.2f}")
    else:
        print("\nDecision: CREATE NEW KB ARTICLE (no strong title match found).")
        if matched_title:
            print(f"Closest Match: {matched_title}  [Score={score:.2f}]")
            print(f"Article ID:    {matched_id or '(unknown)'}")
            print(f"URL:           {matched_url or '(none)'}")
        else:
            print("Closest Match: (none)")
    decision_path = BASE_OUT / "kb_match_decision.json"
    with open(decision_path, "w", encoding="utf-8") as jf:
        json.dump(decision, jf, indent=2, ensure_ascii=False)
    print("\nDecision JSON saved to:", decision_path.resolve())

    # ---- Step 3b: build merged manuals
    print("\n>> Step 3b: Matching Confluence & Zoho PDFs from folders and creating merged manual(s)â€¦")
    created_map: Dict[str, Path] = {}
    if REPORTLAB_OK and PYPDF_OK:
        try:
            created_map = build_lossless_manuals_from_folders(CONFLUENCE_PATH, ZOHO_PATH, OUTPUT_DIR, TITLE_THRESHOLD)
        except Exception as e:
            print(f"[error] While building merged manuals: {e}")
            created_map = {}
    else:
        print("[warn] Skipping merge: install both 'reportlab' and 'pypdf' to enable PDF creation.")

    merged_pdf_to_send: Optional[Path] = None
    if created_map:
        conf_name = PDF_PATH.name
        merged_pdf_to_send = created_map.get(conf_name) or next(iter(created_map.values()))
        print(f"\nSelected merged PDF to email: {merged_pdf_to_send}")
    else:
        print("\n[warn] No merged manuals were created; email will be sent WITHOUT attachment.")

    # ---- Step 4: email (hardened)
    print("\n>> Step 4: Emailing the merged PDF to manager for reviewâ€¦")

    # Strip whitespace and enforce no spaces in app passwords
    me_addr      = (os.getenv("SENDER_EMAIL", "usman.verbinden@gmail.com") or "").strip()
    manager_addr = (os.getenv("MANAGER_EMAIL", "usman.alot761@gmail.com") or "").strip()

    smtp_user = (os.getenv("SMTP_USER", me_addr) or "").strip()
    smtp_pass = (os.getenv("SMTP_PASS", "") or "").strip().replace(" ", "")
    imap_user = (os.getenv("IMAP_USER", me_addr) or "").strip()
    imap_pass = (os.getenv("IMAP_PASS", "") or "").strip().replace(" ", "")

    print("SMTP user:", smtp_user)
    print("SMTP pass len:", len(smtp_pass))

    if not smtp_pass or not imap_pass:
        print("[error] Missing SMTP_PASS/IMAP_PASS env vars. Skipping email send + wait for reply.")
        print("\nâœ… Done."); return

    # Attachment size guard (~22MB practical limit)
    attachment_arg = merged_pdf_to_send if _is_valid_file(merged_pdf_to_send) else None
    if attachment_arg:
        size_mb = attachment_arg.stat().st_size / (1024*1024)
        print(f"Attachment: {attachment_arg} ({size_mb:.2f} MB)")
        if size_mb > 22:
            print("[warn] Attachment > ~22 MB. Sending WITHOUT attachment.")
            attachment_arg = None
    else:
        print("[warn] No merged PDF available; sending WITHOUT attachment.")

    # SSL preflight (proves connection+auth in THIS process)
    import ssl, smtplib
    try:
        print("Preflight: connecting/login via SSL:465â€¦")
        with smtplib.SMTP_SSL("smtp.gmail.com", 465, context=ssl.create_default_context(), timeout=30) as s:
            if os.getenv("SMTP_DEBUG","0") == "1": s.set_debuglevel(1)
            s.login(smtp_user, smtp_pass)
            code, resp = s.noop()
            print("Preflight OK:", code, resp)
    except Exception as e:
        print("[fatal] SMTP preflight failed:", e)
        print("\nâœ… Done."); return

    subject = f"[KB Review] {meta['title']}"
    body = (
        "Hi,\n\n"
        "Please review the attached merged manual (lossless) generated from the Zoho KB PDF and the matching Confluence PDF.\n\n"
        f"Decision: {('UPDATE existing' if decision.get('action')=='update' else 'CREATE new')} KB\n"
        f"Matched Title: {decision.get('matched_title') or '(none)'}\n"
        f"Matched URL: {decision.get('matched_url') or '(none)'}\n"
        f"Matched ID: {decision.get('matched_id') or '(none)'}\n"
        f"Score: {decision.get('score', 0.0)}\n\n"
        "Thanks!\n"
    )

    try:
        send_email_with_attachment_smtp(
            subject=subject,
            body=body,
            to_addrs=[manager_addr],
            cc_addrs=[me_addr],
            attachment_path=attachment_arg,
            smtp_user=smtp_user,
            smtp_pass=smtp_pass,
        )
        print("âœ… Email sent to manager:", manager_addr)
    except Exception as e:
        print("[error] Failed to send email:", e)
        print("\nâœ… Done."); return

    # Optional: wait for a reply
    wait_minutes = int(os.getenv("WAIT_FOR_REPLY_MINUTES", "0"))
    if wait_minutes > 0:
        print(f">> Waiting up to {wait_minutes} minute(s) for a reply from {manager_addr}â€¦")
        reply = wait_for_reply_imap(
            original_subject=subject,
            expect_from=manager_addr,
            imap_user=imap_user,
            imap_pass=imap_pass,
            timeout_minutes=wait_minutes,
            poll_interval_seconds=15,
        )
        if reply.get("found"):
            print("\nâœ… Manager reply received:")
            print("From:   ", reply["from"])
            print("Date:   ", reply["date"])
            print("Subject:", reply["subject"])
            print("\n--- Reply Body (first 5k chars) ---\n")
            print(reply["body"])
            print("\n--- End Reply ---\n")
        else:
            print("\n(no reply received within the wait window)")
    else:
        print("(not waiting for reply; set WAIT_FOR_REPLY_MINUTES>0 to enable)")

    print("\nâœ… Done.")

if __name__ == "__main__":
    main()
